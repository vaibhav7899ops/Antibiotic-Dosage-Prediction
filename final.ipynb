{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b593981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sh/q5490jss67b8ntl_ghcyl5dm0000gn/T/ipykernel_27246/1624793117.py:15: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shape: (16431, 135)\n",
      "Vital vector length (target_len): 4\n",
      "X_cluster_raw shape: (16431, 142)\n",
      "\n",
      "Mortality by cluster:\n",
      "cluster\n",
      "0    0.000000\n",
      "1    0.162529\n",
      "2    0.181435\n",
      "3    0.013333\n",
      "Name: is_dead, dtype: float64\n",
      "\n",
      "Mortality threshold: 0.08793140540316909\n",
      "Bad (poor-response) clusters: [1, 2]\n",
      "\n",
      "Sweet-spot dose ranges (good responders):\n",
      "abx__Cephalexin: n=75 | q25=500.00, median=500.00, q75=500.00\n",
      "\n",
      "Classifier trained. Class counts: [   80 16351]\n",
      "Saved with predictions to: output_with_prediction.csv\n",
      "\n",
      "Prediction counts:\n",
      "final_prediction\n",
      "increase    16351\n",
      "decrease       80\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Prediction proportions:\n",
      "final_prediction\n",
      "increase    0.995131\n",
      "decrease    0.004869\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "csv_path = \"output_with_is_dead.csv\"   \n",
    "df = pd.read_csv(csv_path)\n",
    "print(\"Loaded shape:\", df.shape)\n",
    "\n",
    "\n",
    "vital_cols = [\"AT_START\", \"After_6hr\", \"After_12hr\", \"After_18hr\", \"After_24hr\"]\n",
    "for col in vital_cols:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Required column '{col}' not found in CSV.\")\n",
    "\n",
    "def parse_vital_string(s):\n",
    "    \"\"\"\n",
    "    Parse '[..]' string into np.array of floats.\n",
    "    'Undefined', 'nan', 'none', '' -> NaN inside the array.\n",
    "    \"\"\"\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    try:\n",
    "        arr = ast.literal_eval(str(s))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    vals = []\n",
    "    for x in arr:\n",
    "        if isinstance(x, str):\n",
    "            if x.strip().lower() in [\"undefined\", \"nan\", \"none\", \"\"]:\n",
    "                vals.append(np.nan)\n",
    "            else:\n",
    "                try:\n",
    "                    vals.append(float(x))\n",
    "                except Exception:\n",
    "                    vals.append(np.nan)\n",
    "        else:\n",
    "            try:\n",
    "                vals.append(float(x))\n",
    "            except Exception:\n",
    "                vals.append(np.nan)\n",
    "    return np.array(vals, dtype=float)\n",
    "\n",
    "parsed_vitals = {col: df[col].apply(parse_vital_string) for col in vital_cols}\n",
    "\n",
    "lengths = [\n",
    "    len(a) for a in parsed_vitals[\"AT_START\"]\n",
    "    if a is not None\n",
    "]\n",
    "if not lengths:\n",
    "    raise ValueError(\"No valid AT_START vitals parsed.\")\n",
    "target_len = Counter(lengths).most_common(1)[0][0]\n",
    "print(\"Vital vector length (target_len):\", target_len)\n",
    "\n",
    "def vitals_to_matrix(series, target_len):\n",
    "    \"\"\"\n",
    "    Convert a Series of arrays into (n_rows, target_len) matrix.\n",
    "    - None -> all-NaN row\n",
    "    - longer -> truncate\n",
    "    - shorter -> pad with NaN\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for arr in series:\n",
    "        if arr is None:\n",
    "            rows.append(np.full(target_len, np.nan))\n",
    "            continue\n",
    "        a = np.array(arr, dtype=float)\n",
    "        if a.shape[0] > target_len:\n",
    "            a = a[:target_len]\n",
    "        elif a.shape[0] < target_len:\n",
    "            pad = np.full(target_len - a.shape[0], np.nan)\n",
    "            a = np.concatenate([a, pad])\n",
    "        rows.append(a)\n",
    "    return np.vstack(rows)\n",
    "\n",
    "# Vitals matrices for all rows (may contain NaNs)\n",
    "v_start = vitals_to_matrix(parsed_vitals[\"AT_START\"],   target_len)\n",
    "v_6     = vitals_to_matrix(parsed_vitals[\"After_6hr\"],  target_len)\n",
    "v_12    = vitals_to_matrix(parsed_vitals[\"After_12hr\"], target_len)\n",
    "v_18    = vitals_to_matrix(parsed_vitals[\"After_18hr\"], target_len)\n",
    "v_24    = vitals_to_matrix(parsed_vitals[\"After_24hr\"], target_len)\n",
    "\n",
    "# =========================================\n",
    "# 3. Vector-space features for clustering\n",
    "#    (AT_START + deltas + dose + abx one-hot)\n",
    "# =========================================\n",
    "delta_6  = v_6  - v_start\n",
    "delta_12 = v_12 - v_start\n",
    "delta_18 = v_18 - v_start\n",
    "delta_24 = v_24 - v_start\n",
    "\n",
    "# Dose\n",
    "if \"DOSE_VAL_RX\" not in df.columns:\n",
    "    raise ValueError(\"'DOSE_VAL_RX' column missing.\")\n",
    "dose_raw = pd.to_numeric(df[\"DOSE_VAL_RX\"], errors=\"coerce\").values.reshape(-1, 1)\n",
    "\n",
    "# Antibiotics one-hot\n",
    "abx_cols = [c for c in df.columns if c.startswith(\"abx__\")]\n",
    "if abx_cols:\n",
    "    abx_raw = df[abx_cols].apply(pd.to_numeric, errors=\"coerce\").values\n",
    "else:\n",
    "    abx_raw = None\n",
    "    print(\"âš  No 'abx__' columns found; antibiotic info won't be used.\")\n",
    "\n",
    "# Build clustering feature matrix\n",
    "X_cluster_parts = [\n",
    "    v_start,\n",
    "    delta_6,\n",
    "    delta_12,\n",
    "    delta_18,\n",
    "    delta_24,\n",
    "    dose_raw,\n",
    "]\n",
    "if abx_raw is not None:\n",
    "    X_cluster_parts.append(abx_raw)\n",
    "\n",
    "X_cluster_raw = np.hstack(X_cluster_parts)\n",
    "print(\"X_cluster_raw shape:\", X_cluster_raw.shape)\n",
    "\n",
    "# Impute (median) + scale for KMeans (df itself untouched)\n",
    "imp_cluster = SimpleImputer(strategy=\"median\")\n",
    "X_cluster_imp = imp_cluster.fit_transform(X_cluster_raw)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_cluster_scaled = scaler.fit_transform(X_cluster_imp)\n",
    "\n",
    "# =========================================\n",
    "# 4. KMeans clustering on ALL rows\n",
    "# =========================================\n",
    "K = 4\n",
    "kmeans = KMeans(n_clusters=K, random_state=42, n_init=\"auto\")\n",
    "cluster_labels = kmeans.fit_predict(X_cluster_scaled)\n",
    "cluster_series = pd.Series(cluster_labels, index=df.index)\n",
    "\n",
    "# =========================================\n",
    "# 5. Mortality per cluster -> poor_response pseudo-labels\n",
    "# =========================================\n",
    "if \"is_dead\" not in df.columns:\n",
    "    raise ValueError(\"'is_dead' column missing.\")\n",
    "\n",
    "mort_df = pd.DataFrame({\n",
    "    \"cluster\": cluster_series,\n",
    "    \"is_dead\": pd.to_numeric(df[\"is_dead\"], errors=\"coerce\")\n",
    "})\n",
    "\n",
    "cluster_mortality = (\n",
    "    mort_df\n",
    "    .dropna(subset=[\"is_dead\"])\n",
    "    .groupby(\"cluster\")[\"is_dead\"]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "print(\"\\nMortality by cluster:\")\n",
    "print(cluster_mortality)\n",
    "\n",
    "# If some clusters missing mortality (no is_dead data), fill with global mean\n",
    "\n",
    "if len(cluster_mortality) < K:\n",
    "    overall_mean = cluster_mortality.mean()\n",
    "    for c in range(K):\n",
    "        if c not in cluster_mortality.index:\n",
    "            cluster_mortality.loc[c] = overall_mean\n",
    "    cluster_mortality = cluster_mortality.sort_index()\n",
    "\n",
    "mort_threshold = float(cluster_mortality.median())\n",
    "bad_clusters = cluster_mortality[cluster_mortality > mort_threshold].index.tolist()\n",
    "\n",
    "print(\"\\nMortality threshold:\", mort_threshold)\n",
    "print(\"Bad (poor-response) clusters:\", bad_clusters)\n",
    "\n",
    "cluster_to_poor = {c: int(c in bad_clusters) for c in range(K)}\n",
    "poor_response_series = cluster_series.map(cluster_to_poor)  # 0 or 1 for ALL rows\n",
    "\n",
    "# =========================================\n",
    "# 6. Sweet-spot dose per antibiotic (good responders only)\n",
    "# =========================================\n",
    "sweet_spots = {}\n",
    "\n",
    "if abx_cols:\n",
    "    good_idx = poor_response_series[poor_response_series == 0].index\n",
    "    df_good = df.loc[good_idx]\n",
    "\n",
    "    for abx in abx_cols:\n",
    "        doses_abx = pd.to_numeric(\n",
    "            df_good.loc[df_good[abx] == 1, \"DOSE_VAL_RX\"],\n",
    "            errors=\"coerce\"\n",
    "        ).dropna().values\n",
    "        if len(doses_abx) < 10:\n",
    "            continue\n",
    "        q25, q50, q75 = np.percentile(doses_abx, [25, 50, 75])\n",
    "        sweet_spots[abx] = {\n",
    "            \"q25\": q25,\n",
    "            \"q50\": q50,\n",
    "            \"q75\": q75,\n",
    "            \"n\": len(doses_abx),\n",
    "        }\n",
    "\n",
    "print(\"\\nSweet-spot dose ranges (good responders):\")\n",
    "for abx, info in sweet_spots.items():\n",
    "    print(f\"{abx}: n={info['n']} | q25={info['q25']:.2f}, median={info['q50']:.2f}, q75={info['q75']:.2f}\")\n",
    "\n",
    "# =========================================\n",
    "# 7. Classifier: predict poor_response (0/1) for all rows\n",
    "#    Features: AT_START + dose + abx\n",
    "# =========================================\n",
    "X_clf_parts = [v_start, dose_raw]\n",
    "if abx_raw is not None:\n",
    "    X_clf_parts.append(abx_raw)\n",
    "\n",
    "X_clf_raw = np.hstack(X_clf_parts)\n",
    "y_clf = poor_response_series.values\n",
    "\n",
    "imp_clf = SimpleImputer(strategy=\"median\")\n",
    "X_clf_imp = imp_clf.fit_transform(X_clf_raw)\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "clf.fit(X_clf_imp, y_clf)\n",
    "\n",
    "print(\"\\nClassifier trained. Class counts:\", np.bincount(y_clf))\n",
    "\n",
    "# Probability of poor response for ALL rows\n",
    "prob_all = clf.predict_proba(X_clf_imp)\n",
    "prob_poor_all = prob_all[:, 1]  # P(poor_response = 1)\n",
    "\n",
    "# =========================================\n",
    "# 8. Final decision: \"increase\" / \"decrease\"\n",
    "#    Purely based on prob_poor + sweet-spot\n",
    "# =========================================\n",
    "\n",
    "dose_series = pd.to_numeric(df[\"DOSE_VAL_RX\"], errors=\"coerce\")\n",
    "\n",
    "def pick_main_abx(row, abx_columns):\n",
    "    \"\"\"Pick first abx__* with value == 1 (if any).\"\"\"\n",
    "    if not abx_columns:\n",
    "        return None\n",
    "    for abx in abx_columns:\n",
    "        val = row.get(abx)\n",
    "        try:\n",
    "            if float(val) == 1.0:\n",
    "                return abx\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "def dose_zone_and_thresholds(dose_value, abx_name, sweet_spots_dict):\n",
    "    \"\"\"\n",
    "    Return (zone, low_q, high_q) where:\n",
    "      zone in {\"below\", \"in\", \"above\", \"unknown\"}\n",
    "    \"\"\"\n",
    "    if pd.isna(dose_value) or abx_name not in sweet_spots_dict:\n",
    "        return \"unknown\", None, None\n",
    "\n",
    "    ss = sweet_spots_dict[abx_name]\n",
    "    low, high = ss[\"q25\"], ss[\"q75\"]\n",
    "\n",
    "    if dose_value < low:\n",
    "        return \"below\", low, high\n",
    "    elif dose_value > high:\n",
    "        return \"above\", low, high\n",
    "    else:\n",
    "        return \"in\", low, high\n",
    "\n",
    "def decide_increase_or_decrease(prob_poor, dose_value, abx_name, sweet_spots_dict):\n",
    "    \"\"\"\n",
    "    Clinically motivated, threshold-based logic:\n",
    "\n",
    "    - HIGH_RISK_THR: probability above which we treat as clearly high risk\n",
    "    - MID_RISK_THR:  probability above which, if dose is below sweet-spot,\n",
    "                     we are okay to increase\n",
    "\n",
    "    Cases:\n",
    "      1) zone == \"above\"  -> always \"decrease\"\n",
    "      2) zone == \"below\"  ->\n",
    "           if prob_poor >= MID_RISK_THR  -> \"increase\"\n",
    "           else                          -> \"decrease\"\n",
    "      3) zone == \"in\"     ->\n",
    "           always \"decrease\" (no escalation from sweet-spot in this 2-label setup)\n",
    "      4) zone == \"unknown\" ->\n",
    "           if prob_poor >= HIGH_RISK_THR -> \"increase\"\n",
    "           else                          -> \"decrease\"\n",
    "    \"\"\"\n",
    "    if prob_poor is None or np.isnan(prob_poor):\n",
    "        return \"decrease\"  # safe default\n",
    "\n",
    "    # tune yaha se: kaafi aggressive/ conservative ban sakta hai\n",
    "    HIGH_RISK_THR = 0.75\n",
    "    MID_RISK_THR  = 0.55\n",
    "\n",
    "    zone, low_q, high_q = dose_zone_and_thresholds(dose_value, abx_name, sweet_spots_dict)\n",
    "\n",
    "    # 1) Already above sweet-spot: never increase\n",
    "    if zone == \"above\":\n",
    "        return \"decrease\"\n",
    "\n",
    "    # 2) Dose below sweet-spot\n",
    "    if zone == \"below\":\n",
    "        if prob_poor >= MID_RISK_THR:\n",
    "            return \"increase\"\n",
    "        else:\n",
    "            return \"decrease\"\n",
    "\n",
    "    # 3) Dose within sweet-spot range\n",
    "    if zone == \"in\":\n",
    "        # In real life you might 'switch' drug; hamare 2-label world me\n",
    "        # \"no further escalation\" ko \"decrease\" treat kar rahe hain.\n",
    "        return \"decrease\"\n",
    "\n",
    "    # 4) Unknown zone (no sweet-spot info or no dose)\n",
    "    if zone == \"unknown\":\n",
    "        if prob_poor >= HIGH_RISK_THR:\n",
    "            return \"increase\"\n",
    "        else:\n",
    "            return \"decrease\"\n",
    "\n",
    "    # Fallback (should not reach here)\n",
    "    return \"decrease\"\n",
    "\n",
    "# -----------------------------------------\n",
    "# 8.1 Loop over rows and apply decision\n",
    "# -----------------------------------------\n",
    "final_preds = []\n",
    "\n",
    "for i, (idx, row) in enumerate(df.iterrows()):\n",
    "    prob_poor = prob_poor_all[i]\n",
    "    dose_val = dose_series.iloc[i]\n",
    "    main_abx = pick_main_abx(row, abx_cols)\n",
    "    pred_label = decide_increase_or_decrease(\n",
    "        prob_poor=prob_poor,\n",
    "        dose_value=dose_val,\n",
    "        abx_name=main_abx,\n",
    "        sweet_spots_dict=sweet_spots,\n",
    "    )\n",
    "    final_preds.append(pred_label)\n",
    "\n",
    "# =========================================\n",
    "# 9. Add ONLY ONE new column + save\n",
    "# =========================================\n",
    "df[\"final_prediction\"] = final_preds  # original columns unchanged\n",
    "\n",
    "out_path = \"output_with_prediction.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "print(\"Saved with predictions to:\", out_path)\n",
    "\n",
    "print(\"\\nPrediction counts:\")\n",
    "print(df[\"final_prediction\"].value_counts())\n",
    "print(\"\\nPrediction proportions:\")\n",
    "print(df[\"final_prediction\"].value_counts(normalize=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
